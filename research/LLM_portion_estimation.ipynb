{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oxphxtqReMd"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from getpass import getpass\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import json\n",
        "\n",
        "from typing import List\n",
        "from pydantic import BaseModel, confloat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input api key\n",
        "# get from https://openai.com/api/\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "#gpt api\n",
        "gpt_client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "RLqjWXZRRqsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert image to base64 to pass into openai api\n",
        "def image_to_base64(img):\n",
        "    \"\"\"Convert a PIL Image to a base64 data URI for OpenAI API.\"\"\"\n",
        "    buffer = BytesIO()\n",
        "    img.save(buffer, format=\"JPEG\")  # or \"PNG\" if you prefer\n",
        "    b64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "    return f\"data:image/jpeg;base64,{b64}\""
      ],
      "metadata": {
        "id": "v9h13GDwRxD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# huskyeats api helpers\n",
        "import requests\n",
        "\n",
        "def get_nutrition_info(item_id):\n",
        "    url = \"https://husky-eats.onrender.com/api/menuitem/\" + str(item_id)\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "    return r.json()"
      ],
      "metadata": {
        "id": "pDbwXUGnR8hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pydantic Output Classes\n",
        "class ClassifiedItem(BaseModel):\n",
        "    id: int\n",
        "    name: str\n",
        "    confidence: confloat(ge=0.0, le=1.0)\n",
        "\n",
        "class ClassificationResult(BaseModel):\n",
        "    items: List[ClassifiedItem]   # [{id,name,confidence}, ...]\n",
        "    explanation: str"
      ],
      "metadata": {
        "id": "IsSwH_7YRopA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt model 2, portion estimation\n",
        "def gpt_portion_estimation(pil_img, classification_result, client, model=\"gpt-5-mini\"):\n",
        "    image_url = image_to_base64(pil_img)\n",
        "\n",
        "    for item in classification_result[\"items\"]:\n",
        "      item[\"nutrition\"] = get_nutrition_info(item[\"id\"])\n",
        "\n",
        "    payload = json.dumps(classification_result, indent=2)\n",
        "\n",
        "    prompt_text = (\n",
        "        \"You are a nutrition analyst estimating portion sizes.\\n\\n\"\n",
        "        \"INPUTS:\\n\"\n",
        "        \"1) An image of a single plate.\\n\"\n",
        "        \"2) A JSON of detected items with nutrition info, including serving size.\\n\\n\"\n",
        "        \"TASK:\\n\"\n",
        "        \"- For each detected item, output ONLY the number of SERVINGS on the plate, as a decimal if needed.\\n\"\n",
        "        \"- If serving size uses EACH and shows a number N (e.g., '4 EACH'), then 1 serving = N pieces. \"\n",
        "        \"  If you estimate P pieces on the plate, report servings = P / N.\\n\"\n",
        "        \"- For non-EACH units (g/oz/cup), estimate servings by dividing the visible amount by the serving size.\\n\"\n",
        "        \"- Do not output the piece count (P). Do not output words like 'tenders' or any free text other than the explanation field.\\n\"\n",
        "        \"- Do not invent items. Only return items present in the provided JSON.\\n\"\n",
        "        \"- Include the count in explanation for EACH type items.\\n\"\n",
        "        \"- If unsure, return your best conservative estimate.\\n\\n\"\n",
        "        \"FORMAT (strict JSON):\\n\"\n",
        "        \"{\\n\"\n",
        "        '  \"servings\": [ { \"id\": <int>, \"name\": \"<str>\", \"estimated_servings\": <float> }, ... ],\\n'\n",
        "        '  \"explanation\": \"<1-2 short sentences>\"\\n'\n",
        "        \"}\\n\"\n",
        "    )\n",
        "\n",
        "    response = client.responses.parse(\n",
        "        model=model,\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"input_text\", \"text\": prompt_text},\n",
        "                    {\"type\": \"input_text\", \"text\": payload},\n",
        "                    {\"type\": \"input_image\", \"image_url\": image_url}\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        text_format=PortionEstimationResult\n",
        "    )\n",
        "\n",
        "    return response.output_parsed.model_dump()"
      ],
      "metadata": {
        "id": "cfB-np5NR2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output\n",
        "classification_result = gpt_item_classification(pil_image, items_ranked, gpt_client)\n",
        "portion_estimates = gpt_portion_estimation(pil_image, classification_result, gpt_client)"
      ],
      "metadata": {
        "id": "y50dPt5pSU1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}