{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copy the long code block below to test any pipeline with the normal 4 inputs (image, dining_hall_id, mealtime, date) and list of outputs (items + num_servings per item).\n",
        "\n",
        "The pipeline **must** define a `predict()` function with the following definition:\n",
        "\n",
        "```python3\n",
        "\n",
        "@dataclass\n",
        "class PredictedItem:\n",
        "    id: str\n",
        "    num_servings: float\n",
        "\n",
        "def predict(image, dining_hall_id, meal_time, date) -> [PredictedItem]:\n",
        "    return [\n",
        "      PredictedItem(id=\"12345\", num_servings=1.0),\n",
        "      PredictedItem(id=\"67890\", num_servings=0.5),\n",
        "    ]\n",
        "```"
      ],
      "metadata": {
        "id": "-XSSPliQaNod"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbSV7yZAWgUh"
      },
      "outputs": [],
      "source": [
        "# ---- CONFIG ----\n",
        "from getpass import getpass\n",
        "\n",
        "API_BASE_URL = \"https://3vw53n9900.execute-api.us-east-1.amazonaws.com/dev\"\n",
        "API_TOKEN = getpass(\"Enter MenuMatch API token: \")\n",
        "\n",
        "HUSKYEATS_BASE_URL = \"https://husky-eats.onrender.com/api\"\n",
        "\n",
        "# ---- IMPORTS ----\n",
        "import requests\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Any, Iterable, Tuple\n",
        "from io import BytesIO\n",
        "import math\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# ---- LOW-LEVEL API HELPERS ----\n",
        "\n",
        "def _auth_headers() -> Dict[str, str]:\n",
        "    return {\"X-Api-Key\": API_TOKEN}\n",
        "\n",
        "\n",
        "def fetch_dataset_metadata() -> List[Dict[str, Any]]:\n",
        "    url = f\"{API_BASE_URL}/dataset\"\n",
        "    resp = requests.get(url, headers=_auth_headers())\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    return data.get(\"items\", data)\n",
        "\n",
        "\n",
        "def get_download_url(object_key: str, bucket: Optional[str] = None) -> str:\n",
        "    url = f\"{API_BASE_URL}/downloads/presign\"\n",
        "    payload: Dict[str, Any] = {\"objectKey\": object_key}\n",
        "    if bucket:\n",
        "        payload[\"bucket\"] = bucket\n",
        "\n",
        "    resp = requests.post(url, headers=_auth_headers(), json=payload)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    return data[\"downloadUrl\"]\n",
        "\n",
        "\n",
        "def load_image(object_key: str, bucket: Optional[str] = None) -> Image.Image:\n",
        "    download_url = get_download_url(object_key, bucket=bucket)\n",
        "    resp = requests.get(download_url)\n",
        "    resp.raise_for_status()\n",
        "    img = Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_nutrition_for_id(menu_item_id):\n",
        "    # HuskyEats: GET /menuitem/{id}\n",
        "    url = f\"{HUSKYEATS_BASE_URL}/menuitem/{menu_item_id}\"\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "\n",
        "    return {\n",
        "        \"kcal\": float(data[\"calories\"]),\n",
        "        \"protein_g\": float(data[\"protein_g\"]),\n",
        "        \"carb_g\": float(data[\"totalcarbohydrate_g\"]),\n",
        "        \"fat_g\": float(data[\"totalfat_g\"]),\n",
        "    }\n",
        "\n",
        "\n",
        "# ---- DATA STRUCTURES ----\n",
        "\n",
        "@dataclass\n",
        "class GroundTruthItem:\n",
        "    id: str\n",
        "    num_servings: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Sample:\n",
        "    object_key: str\n",
        "    image: Image.Image\n",
        "    dining_hall_id: str\n",
        "    meal_time: str\n",
        "    date: str\n",
        "    difficulty: Optional[str]\n",
        "    ground_truth: List[GroundTruthItem]\n",
        "\n",
        "\n",
        "def iter_samples(limit: Optional[int] = None) -> Iterable[Sample]:\n",
        "    metadata_items = fetch_dataset_metadata()\n",
        "    if limit is not None:\n",
        "        metadata_items = metadata_items[:limit]\n",
        "\n",
        "    for meta in metadata_items:\n",
        "        object_key = meta[\"objectKey\"]\n",
        "        bucket = meta.get(\"bucket\")\n",
        "\n",
        "        img = load_image(object_key, bucket=bucket)\n",
        "\n",
        "        gt_items = [\n",
        "            GroundTruthItem(\n",
        "                id=str(item[\"menuItemId\"]),\n",
        "                num_servings=float(item[\"servings\"]),\n",
        "            )\n",
        "            for item in meta.get(\"items\", [])\n",
        "        ]\n",
        "\n",
        "        yield Sample(\n",
        "            object_key=object_key,\n",
        "            image=img,\n",
        "            dining_hall_id=str(meta.get(\"diningHallId\")),\n",
        "            meal_time=str(meta.get(\"mealtime\")),\n",
        "            date=str(meta.get(\"mealDate\")),\n",
        "            difficulty=meta.get(\"difficulty\"),\n",
        "            ground_truth=gt_items,\n",
        "        )\n",
        "\n",
        "\n",
        "# ---- RUNNER ----\n",
        "\n",
        "def run_model_on_dataset(\n",
        "    predict_fn=None,\n",
        "    limit: Optional[int] = None,\n",
        "):\n",
        "    if predict_fn is None:\n",
        "        try:\n",
        "            predict_fn = globals()[\"predict\"]\n",
        "        except KeyError:\n",
        "            raise ValueError(\"No predict_fn provided and no global `predict` defined.\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for sample in iter_samples(limit=limit):\n",
        "        preds = predict_fn(\n",
        "            sample.image,\n",
        "            sample.dining_hall_id,\n",
        "            sample.meal_time,\n",
        "            sample.date,\n",
        "        )\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"object_key\": sample.object_key,\n",
        "                \"dining_hall_id\": sample.dining_hall_id,\n",
        "                \"meal_time\": sample.meal_time,\n",
        "                \"date\": sample.date,\n",
        "                \"ground_truth\": sample.ground_truth,\n",
        "                \"predictions\": preds,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ---- METRICS ----\n",
        "\n",
        "def _items_to_dict(items: Iterable[Any]) -> Dict[str, float]:\n",
        "    out: Dict[str, float] = {}\n",
        "    for it in items:\n",
        "        if hasattr(it, \"id\"):\n",
        "            _id = str(it.id)\n",
        "            servings = float(it.num_servings)\n",
        "        else:\n",
        "            _id = str(it[\"id\"])\n",
        "            servings = float(it.get(\"num_servings\", 0.0))\n",
        "        out[_id] = servings\n",
        "    return out\n",
        "\n",
        "\n",
        "def compute_all_metrics(\n",
        "    results: List[Dict[str, Any]],\n",
        "    get_nutrition_for_id: Optional[callable] = None,\n",
        "    macro_nutrients: Tuple[str, ...] = (\"kcal\", \"protein_g\", \"carb_g\", \"fat_g\"),\n",
        ") -> Dict[str, float]:\n",
        "    tp = fp = fn = 0\n",
        "    jaccards: List[float] = []\n",
        "    exact_match_count = 0\n",
        "\n",
        "    abs_errors: List[float] = []\n",
        "    sq_errors: List[float] = []\n",
        "    perc_errors: List[float] = []\n",
        "\n",
        "    for r in results:\n",
        "        gt = _items_to_dict(r[\"ground_truth\"])\n",
        "        pr = _items_to_dict(r[\"predictions\"])\n",
        "\n",
        "        gt_ids = {k for k, v in gt.items() if v > 0}\n",
        "        pr_ids = {k for k, v in pr.items() if v > 0}\n",
        "\n",
        "        inter = gt_ids & pr_ids\n",
        "        tp += len(inter)\n",
        "        fp += len(pr_ids - gt_ids)\n",
        "        fn += len(gt_ids - pr_ids)\n",
        "\n",
        "        union = gt_ids | pr_ids\n",
        "        j = len(inter) / len(union) if union else 1.0\n",
        "        jaccards.append(j)\n",
        "\n",
        "        if gt_ids == pr_ids:\n",
        "            exact_match_count += 1\n",
        "\n",
        "        all_ids = set(gt.keys()) | set(pr.keys())\n",
        "        for item_id in all_ids:\n",
        "            g = gt.get(item_id, 0.0)\n",
        "            p = pr.get(item_id, 0.0)\n",
        "            err = p - g\n",
        "            ae = abs(err)\n",
        "            abs_errors.append(ae)\n",
        "            sq_errors.append(err * err)\n",
        "            if g > 0:\n",
        "                perc_errors.append(ae / g)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    avg_jaccard = sum(jaccards) / len(jaccards) if jaccards else 0.0\n",
        "    exact_match = exact_match_count / len(results) if results else 0.0\n",
        "\n",
        "    mae_serv = sum(abs_errors) / len(abs_errors) if abs_errors else 0.0\n",
        "    rmse_serv = math.sqrt(sum(sq_errors) / len(sq_errors)) if sq_errors else 0.0\n",
        "    pmae_serv = sum(perc_errors) / len(perc_errors) if perc_errors else 0.0\n",
        "\n",
        "    metrics: Dict[str, float] = {\n",
        "        \"cls_precision\": precision,\n",
        "        \"cls_recall\": recall,\n",
        "        \"cls_f1\": f1,\n",
        "        \"cls_avg_jaccard\": avg_jaccard,\n",
        "        \"cls_exact_match\": exact_match,\n",
        "        \"portion_mae_servings\": mae_serv,\n",
        "        \"portion_rmse_servings\": rmse_serv,\n",
        "        \"portion_pmae_servings\": pmae_serv,\n",
        "    }\n",
        "\n",
        "    if get_nutrition_for_id is not None:\n",
        "        nutr_cache: Dict[str, Dict[str, float]] = {}\n",
        "\n",
        "        def nutr(item_id: str) -> Dict[str, float]:\n",
        "            if item_id not in nutr_cache:\n",
        "                nutr_cache[item_id] = get_nutrition_for_id(item_id)\n",
        "            return nutr_cache[item_id]\n",
        "\n",
        "        macro_abs_errors = {n: [] for n in macro_nutrients}\n",
        "        macro_perc_errors = {n: [] for n in macro_nutrients}\n",
        "\n",
        "        for r in results:\n",
        "            gt = _items_to_dict(r[\"ground_truth\"])\n",
        "            pr = _items_to_dict(r[\"predictions\"])\n",
        "\n",
        "            gt_tot = {n: 0.0 for n in macro_nutrients}\n",
        "            pr_tot = {n: 0.0 for n in macro_nutrients}\n",
        "\n",
        "            for item_id, servings in gt.items():\n",
        "                info = nutr(item_id)\n",
        "                for n in macro_nutrients:\n",
        "                    gt_tot[n] += servings * float(info[n])\n",
        "\n",
        "            for item_id, servings in pr.items():\n",
        "                info = nutr(item_id)\n",
        "                for n in macro_nutrients:\n",
        "                    pr_tot[n] += servings * float(info[n])\n",
        "\n",
        "            for n in macro_nutrients:\n",
        "                g = gt_tot[n]\n",
        "                p = pr_tot[n]\n",
        "                ae = abs(p - g)\n",
        "                macro_abs_errors[n].append(ae)\n",
        "                if g > 0:\n",
        "                    macro_perc_errors[n].append(ae / g)\n",
        "\n",
        "        for n in macro_nutrients:\n",
        "            ae_list = macro_abs_errors[n]\n",
        "            pe_list = macro_perc_errors[n]\n",
        "\n",
        "            metrics[f\"macro_mae_{n}\"] = sum(ae_list) / len(ae_list) if ae_list else 0.0\n",
        "            metrics[f\"macro_pmae_{n}\"] = sum(pe_list) / len(pe_list) if pe_list else 0.0\n",
        "\n",
        "    return metrics"
      ]
    }
  ]
}